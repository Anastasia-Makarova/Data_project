{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in /home/stacy/anaconda3/lib/python3.11/site-packages (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/stacy/anaconda3/lib/python3.11/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /home/stacy/anaconda3/lib/python3.11/site-packages (from jiwer) (3.9.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stacy/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-07-27 17:23:04.548975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-27 17:23:04.675735: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-27 17:23:04.713251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-27 17:23:04.922523: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-27 17:23:07.351862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import load_metric\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrOCRProcessor,Seq2SeqTrainer, Seq2SeqTrainingArguments, default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT0913IA.jpg</td>\n",
       "      <td>AT0913IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA6888BH.jpg</td>\n",
       "      <td>CA6888BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KI4108AB.jpg</td>\n",
       "      <td>KI4108AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC1615MC.jpg</td>\n",
       "      <td>BC1615MC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA3002YA.jpg</td>\n",
       "      <td>AA3002YA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name      text\n",
       "0  AT0913IA.jpg  AT0913IA\n",
       "1  CA6888BH.jpg  CA6888BH\n",
       "2  KI4108AB.jpg  KI4108AB\n",
       "3  BC1615MC.jpg  BC1615MC\n",
       "4  AA3002YA.jpg  AA3002YA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ocr_dataset/labels.csv', header=None)\n",
    "df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3)\n",
    "# we reset the indices to start from zero\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "train_dataset = IAMDataset(root_dir='./ocr_dataset/img/',\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = IAMDataset(root_dir='./ocr_dataset/img/',\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 869\n",
      "Number of validation examples: 373\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 384, 384])\n",
      "labels torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=95x61>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(train_dataset.root_dir + train_df['file_name'][0]).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KA0706HT\n"
     ]
    }
   ],
   "source": [
    "labels = encoding['labels']\n",
    "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19119/2056700229.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  cer_metric = load_metric(\"cer\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "cer_metric = load_metric(\"cer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stacy/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    fp16=True, \n",
    "    output_dir=\"./\",\n",
    "    logging_steps=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stacy/anaconda3/lib/python3.11/site-packages/transformers/models/trocr/processing_trocr.py:137: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00de3b043cf545e9a7dfec774ec45f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.1693, 'grad_norm': 101.0296630859375, 'learning_rate': 4.9923371647509584e-05, 'epoch': 0.0}\n",
      "{'loss': 3.0079, 'grad_norm': 174.7723846435547, 'learning_rate': 4.984674329501916e-05, 'epoch': 0.01}\n",
      "{'loss': 5.5139, 'grad_norm': 109.33425903320312, 'learning_rate': 4.977011494252874e-05, 'epoch': 0.01}\n",
      "{'loss': 2.855, 'grad_norm': 61.90847396850586, 'learning_rate': 4.9693486590038316e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5367, 'grad_norm': 82.93531799316406, 'learning_rate': 4.96168582375479e-05, 'epoch': 0.02}\n",
      "{'loss': 1.896, 'grad_norm': 100.90845489501953, 'learning_rate': 4.954022988505747e-05, 'epoch': 0.03}\n",
      "{'loss': 1.4978, 'grad_norm': 41.58099365234375, 'learning_rate': 4.946360153256705e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4571, 'grad_norm': 94.52740478515625, 'learning_rate': 4.938697318007663e-05, 'epoch': 0.04}\n",
      "{'loss': 1.3744, 'grad_norm': 89.43819427490234, 'learning_rate': 4.931034482758621e-05, 'epoch': 0.04}\n",
      "{'loss': 1.432, 'grad_norm': 34.1403694152832, 'learning_rate': 4.9233716475095786e-05, 'epoch': 0.05}\n",
      "{'loss': 1.3913, 'grad_norm': 55.4216194152832, 'learning_rate': 4.915708812260537e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3867, 'grad_norm': 21.639575958251953, 'learning_rate': 4.908045977011494e-05, 'epoch': 0.06}\n",
      "{'loss': 1.0639, 'grad_norm': 69.14519500732422, 'learning_rate': 4.9003831417624524e-05, 'epoch': 0.06}\n",
      "{'loss': 0.9997, 'grad_norm': 38.08147048950195, 'learning_rate': 4.8927203065134106e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4236, 'grad_norm': 43.45646286010742, 'learning_rate': 4.885057471264368e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6413, 'grad_norm': 51.017093658447266, 'learning_rate': 4.877394636015326e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9708, 'grad_norm': 53.44539260864258, 'learning_rate': 4.869731800766284e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0188, 'grad_norm': 527.1546020507812, 'learning_rate': 4.862068965517241e-05, 'epoch': 0.08}\n",
      "{'loss': 3.069, 'grad_norm': 67.75813293457031, 'learning_rate': 4.8544061302681994e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2012, 'grad_norm': 49.64580535888672, 'learning_rate': 4.846743295019157e-05, 'epoch': 0.09}\n",
      "{'loss': 1.5916, 'grad_norm': 34.345252990722656, 'learning_rate': 4.839080459770115e-05, 'epoch': 0.1}\n",
      "{'loss': 2.3187, 'grad_norm': 66.40257263183594, 'learning_rate': 4.831417624521073e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0249, 'grad_norm': 980.8196411132812, 'learning_rate': 4.823754789272031e-05, 'epoch': 0.11}\n",
      "{'loss': 1.3366, 'grad_norm': 47.50920867919922, 'learning_rate': 4.816091954022989e-05, 'epoch': 0.11}\n",
      "{'loss': 2.4146, 'grad_norm': 39.46043014526367, 'learning_rate': 4.8084291187739464e-05, 'epoch': 0.11}\n",
      "{'loss': 1.4755, 'grad_norm': 47.91893768310547, 'learning_rate': 4.8007662835249046e-05, 'epoch': 0.12}\n",
      "{'loss': 1.237, 'grad_norm': 66.97068786621094, 'learning_rate': 4.793103448275863e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0438, 'grad_norm': 47.82038879394531, 'learning_rate': 4.78544061302682e-05, 'epoch': 0.13}\n",
      "{'loss': 1.3159, 'grad_norm': 30.564393997192383, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8018, 'grad_norm': 47.644691467285156, 'learning_rate': 4.770114942528736e-05, 'epoch': 0.14}\n",
      "{'loss': 0.8577, 'grad_norm': 29.271947860717773, 'learning_rate': 4.7624521072796934e-05, 'epoch': 0.14}\n",
      "{'loss': 0.852, 'grad_norm': 41.965457916259766, 'learning_rate': 4.7547892720306516e-05, 'epoch': 0.15}\n",
      "{'loss': 1.0667, 'grad_norm': 36.74057388305664, 'learning_rate': 4.747126436781609e-05, 'epoch': 0.15}\n",
      "{'loss': 0.8274, 'grad_norm': 21.02210235595703, 'learning_rate': 4.739463601532567e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7136, 'grad_norm': 57.34947967529297, 'learning_rate': 4.7318007662835254e-05, 'epoch': 0.16}\n",
      "{'loss': 0.8713, 'grad_norm': 34.491065979003906, 'learning_rate': 4.724137931034483e-05, 'epoch': 0.17}\n",
      "{'loss': 0.8489, 'grad_norm': 23.552391052246094, 'learning_rate': 4.716475095785441e-05, 'epoch': 0.17}\n",
      "{'loss': 1.0898, 'grad_norm': 74.98994445800781, 'learning_rate': 4.7088122605363986e-05, 'epoch': 0.17}\n",
      "{'loss': 0.609, 'grad_norm': 14.570475578308105, 'learning_rate': 4.701149425287357e-05, 'epoch': 0.18}\n",
      "{'loss': 1.3074, 'grad_norm': 38.94369125366211, 'learning_rate': 4.693486590038315e-05, 'epoch': 0.18}\n",
      "{'loss': 0.997, 'grad_norm': 541.4313354492188, 'learning_rate': 4.6858237547892724e-05, 'epoch': 0.19}\n",
      "{'loss': 1.302, 'grad_norm': 139.51235961914062, 'learning_rate': 4.67816091954023e-05, 'epoch': 0.19}\n",
      "{'loss': 2.3675, 'grad_norm': 60.079769134521484, 'learning_rate': 4.6704980842911874e-05, 'epoch': 0.2}\n",
      "{'loss': 2.189, 'grad_norm': 44.83498764038086, 'learning_rate': 4.6628352490421456e-05, 'epoch': 0.2}\n",
      "{'loss': 2.8142, 'grad_norm': 80.59244537353516, 'learning_rate': 4.655172413793104e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4783, 'grad_norm': 86.18197631835938, 'learning_rate': 4.647509578544061e-05, 'epoch': 0.21}\n",
      "{'loss': 1.2497, 'grad_norm': 121.27613067626953, 'learning_rate': 4.6398467432950194e-05, 'epoch': 0.22}\n",
      "{'loss': 1.5782, 'grad_norm': 34.213905334472656, 'learning_rate': 4.632183908045977e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9827, 'grad_norm': 52.06937789916992, 'learning_rate': 4.624521072796935e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9183, 'grad_norm': 50.62146759033203, 'learning_rate': 4.616858237547893e-05, 'epoch': 0.23}\n",
      "{'loss': 1.0947, 'grad_norm': 17.24727439880371, 'learning_rate': 4.609195402298851e-05, 'epoch': 0.23}\n",
      "{'loss': 1.5124, 'grad_norm': 31.81291389465332, 'learning_rate': 4.601532567049809e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7579, 'grad_norm': 39.569969177246094, 'learning_rate': 4.5938697318007664e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9893, 'grad_norm': 33.69518280029297, 'learning_rate': 4.586206896551724e-05, 'epoch': 0.25}\n",
      "{'loss': 1.3012, 'grad_norm': 370.51519775390625, 'learning_rate': 4.578544061302682e-05, 'epoch': 0.25}\n",
      "{'loss': 1.617, 'grad_norm': 54.920711517333984, 'learning_rate': 4.5708812260536396e-05, 'epoch': 0.26}\n",
      "{'loss': 0.7222, 'grad_norm': 29.890504837036133, 'learning_rate': 4.563218390804598e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8871, 'grad_norm': 71.48657989501953, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.27}\n",
      "{'loss': 0.899, 'grad_norm': 20.371315002441406, 'learning_rate': 4.5478927203065134e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7589, 'grad_norm': 22.49663734436035, 'learning_rate': 4.5402298850574716e-05, 'epoch': 0.28}\n",
      "{'loss': 1.0311, 'grad_norm': 49.64412307739258, 'learning_rate': 4.532567049808429e-05, 'epoch': 0.28}\n",
      "{'loss': 0.7439, 'grad_norm': 51.176124572753906, 'learning_rate': 4.524904214559387e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7852, 'grad_norm': 35.85369110107422, 'learning_rate': 4.5172413793103454e-05, 'epoch': 0.29}\n",
      "{'loss': 1.042, 'grad_norm': 14.8493013381958, 'learning_rate': 4.509578544061303e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3853, 'grad_norm': 18.609817504882812, 'learning_rate': 4.501915708812261e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5156, 'grad_norm': 33.79970932006836, 'learning_rate': 4.4942528735632186e-05, 'epoch': 0.3}\n",
      "{'loss': 0.7373, 'grad_norm': 25.042875289916992, 'learning_rate': 4.486590038314176e-05, 'epoch': 0.31}\n",
      "{'loss': 2.0114, 'grad_norm': 24.044410705566406, 'learning_rate': 4.478927203065134e-05, 'epoch': 0.31}\n",
      "{'loss': 3.1617, 'grad_norm': 69.52366638183594, 'learning_rate': 4.471264367816092e-05, 'epoch': 0.32}\n",
      "{'loss': 0.8947, 'grad_norm': 27.149667739868164, 'learning_rate': 4.46360153256705e-05, 'epoch': 0.32}\n",
      "{'loss': 1.29, 'grad_norm': 21.416034698486328, 'learning_rate': 4.455938697318008e-05, 'epoch': 0.33}\n",
      "{'loss': 0.752, 'grad_norm': 39.745296478271484, 'learning_rate': 4.4482758620689656e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4409, 'grad_norm': 76.27116394042969, 'learning_rate': 4.440613026819924e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6224, 'grad_norm': 9.541924476623535, 'learning_rate': 4.432950191570881e-05, 'epoch': 0.34}\n",
      "{'loss': 0.7326, 'grad_norm': 18.572769165039062, 'learning_rate': 4.4252873563218394e-05, 'epoch': 0.34}\n",
      "{'loss': 0.8586, 'grad_norm': 26.456912994384766, 'learning_rate': 4.4176245210727976e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9368, 'grad_norm': 100.26495361328125, 'learning_rate': 4.409961685823755e-05, 'epoch': 0.35}\n",
      "{'loss': 1.1225, 'grad_norm': 33.68287658691406, 'learning_rate': 4.4022988505747126e-05, 'epoch': 0.36}\n",
      "{'loss': 0.8163, 'grad_norm': 57.091190338134766, 'learning_rate': 4.394636015325671e-05, 'epoch': 0.36}\n",
      "{'loss': 0.6697, 'grad_norm': 12.769901275634766, 'learning_rate': 4.386973180076628e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3746, 'grad_norm': 20.18825340270996, 'learning_rate': 4.3793103448275864e-05, 'epoch': 0.37}\n",
      "{'loss': 0.8539, 'grad_norm': 23.950077056884766, 'learning_rate': 4.371647509578544e-05, 'epoch': 0.38}\n",
      "{'loss': 2.5849, 'grad_norm': 83.02252960205078, 'learning_rate': 4.363984674329502e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5565, 'grad_norm': 86.4389419555664, 'learning_rate': 4.35632183908046e-05, 'epoch': 0.39}\n",
      "{'loss': 1.5542, 'grad_norm': 42.47732925415039, 'learning_rate': 4.348659003831418e-05, 'epoch': 0.39}\n",
      "{'loss': 1.3207, 'grad_norm': 73.71979522705078, 'learning_rate': 4.340996168582376e-05, 'epoch': 0.4}\n",
      "{'loss': 1.0366, 'grad_norm': 47.63676452636719, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8263, 'grad_norm': 24.237558364868164, 'learning_rate': 4.3256704980842916e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8423, 'grad_norm': 38.781131744384766, 'learning_rate': 4.31800766283525e-05, 'epoch': 0.41}\n",
      "{'loss': 2.3261, 'grad_norm': 46.238243103027344, 'learning_rate': 4.3103448275862066e-05, 'epoch': 0.41}\n",
      "{'loss': 0.7399, 'grad_norm': 25.424131393432617, 'learning_rate': 4.302681992337165e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6732, 'grad_norm': 63.853477478027344, 'learning_rate': 4.295019157088123e-05, 'epoch': 0.42}\n",
      "{'loss': 0.9554, 'grad_norm': 15.618677139282227, 'learning_rate': 4.2873563218390804e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5855, 'grad_norm': 29.719728469848633, 'learning_rate': 4.2796934865900386e-05, 'epoch': 0.43}\n",
      "{'loss': 0.8404, 'grad_norm': 22.342872619628906, 'learning_rate': 4.272030651340996e-05, 'epoch': 0.44}\n",
      "{'loss': 1.2764, 'grad_norm': 68.43596649169922, 'learning_rate': 4.264367816091954e-05, 'epoch': 0.44}\n",
      "{'loss': 0.7187, 'grad_norm': 11.886205673217773, 'learning_rate': 4.2567049808429124e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2864, 'grad_norm': 8.037606239318848, 'learning_rate': 4.24904214559387e-05, 'epoch': 0.45}\n",
      "{'loss': 0.6757, 'grad_norm': 9.05235767364502, 'learning_rate': 4.241379310344828e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4332, 'grad_norm': 11.330460548400879, 'learning_rate': 4.2337164750957856e-05, 'epoch': 0.46}\n",
      "{'loss': 0.29, 'grad_norm': 19.135738372802734, 'learning_rate': 4.226053639846744e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2876, 'grad_norm': 40.48970413208008, 'learning_rate': 4.218390804597701e-05, 'epoch': 0.47}\n",
      "{'loss': 0.5941, 'grad_norm': 10.829303741455078, 'learning_rate': 4.210727969348659e-05, 'epoch': 0.47}\n",
      "{'loss': 1.4461, 'grad_norm': 226.00160217285156, 'learning_rate': 4.203065134099617e-05, 'epoch': 0.48}\n",
      "{'loss': 0.8225, 'grad_norm': 31.246917724609375, 'learning_rate': 4.195402298850575e-05, 'epoch': 0.48}\n",
      "{'loss': 0.382, 'grad_norm': 76.91004180908203, 'learning_rate': 4.1877394636015326e-05, 'epoch': 0.49}\n",
      "{'loss': 2.4703, 'grad_norm': 70.44872283935547, 'learning_rate': 4.180076628352491e-05, 'epoch': 0.49}\n",
      "{'loss': 0.6671, 'grad_norm': 39.624053955078125, 'learning_rate': 4.172413793103448e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8095, 'grad_norm': 153.6857147216797, 'learning_rate': 4.1647509578544064e-05, 'epoch': 0.5}\n",
      "{'loss': 1.1202, 'grad_norm': 184.1671142578125, 'learning_rate': 4.1570881226053646e-05, 'epoch': 0.51}\n",
      "{'loss': 2.7148, 'grad_norm': 84.835205078125, 'learning_rate': 4.149425287356322e-05, 'epoch': 0.51}\n",
      "{'loss': 3.149, 'grad_norm': 76.73595428466797, 'learning_rate': 4.14176245210728e-05, 'epoch': 0.51}\n",
      "{'loss': 1.1989, 'grad_norm': 33.60979080200195, 'learning_rate': 4.134099616858238e-05, 'epoch': 0.52}\n",
      "{'loss': 1.3372, 'grad_norm': 29.75223731994629, 'learning_rate': 4.126436781609195e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2195, 'grad_norm': 17.683439254760742, 'learning_rate': 4.1187739463601534e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8815, 'grad_norm': 78.46043395996094, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.53}\n",
      "{'loss': 0.5348, 'grad_norm': 29.3061580657959, 'learning_rate': 4.103448275862069e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4243, 'grad_norm': 36.097007751464844, 'learning_rate': 4.095785440613027e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5654, 'grad_norm': 27.765125274658203, 'learning_rate': 4.088122605363985e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2557, 'grad_norm': 26.049152374267578, 'learning_rate': 4.080459770114943e-05, 'epoch': 0.55}\n",
      "{'loss': 1.251, 'grad_norm': 35.25484848022461, 'learning_rate': 4.0727969348659004e-05, 'epoch': 0.56}\n",
      "{'loss': 1.2781, 'grad_norm': 136.5499267578125, 'learning_rate': 4.0651340996168586e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6538, 'grad_norm': 23.227113723754883, 'learning_rate': 4.057471264367817e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7421, 'grad_norm': 54.88081359863281, 'learning_rate': 4.049808429118774e-05, 'epoch': 0.57}\n",
      "{'loss': 0.8589, 'grad_norm': 1261.1536865234375, 'learning_rate': 4.0421455938697324e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3855, 'grad_norm': 20.233875274658203, 'learning_rate': 4.03448275862069e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6024, 'grad_norm': 121.46420288085938, 'learning_rate': 4.0268199233716474e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7076, 'grad_norm': 61.946407318115234, 'learning_rate': 4.0191570881226056e-05, 'epoch': 0.59}\n",
      "{'loss': 0.7378, 'grad_norm': 37.7485466003418, 'learning_rate': 4.011494252873563e-05, 'epoch': 0.59}\n",
      "{'loss': 0.163, 'grad_norm': 11.661025047302246, 'learning_rate': 4.003831417624521e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6224, 'grad_norm': 27.98447608947754, 'learning_rate': 3.9961685823754794e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5915, 'grad_norm': 18.663305282592773, 'learning_rate': 3.988505747126437e-05, 'epoch': 0.61}\n",
      "{'loss': 1.1541, 'grad_norm': 40.18513870239258, 'learning_rate': 3.980842911877395e-05, 'epoch': 0.61}\n",
      "{'loss': 1.2185, 'grad_norm': 15.61409854888916, 'learning_rate': 3.9731800766283526e-05, 'epoch': 0.62}\n",
      "{'loss': 1.3601, 'grad_norm': 9.805217742919922, 'learning_rate': 3.965517241379311e-05, 'epoch': 0.62}\n",
      "{'loss': 2.1057, 'grad_norm': 126.15668487548828, 'learning_rate': 3.957854406130269e-05, 'epoch': 0.63}\n",
      "{'loss': 1.1115, 'grad_norm': 41.82825469970703, 'learning_rate': 3.9501915708812264e-05, 'epoch': 0.63}\n",
      "{'loss': 0.8926, 'grad_norm': 116.57056427001953, 'learning_rate': 3.942528735632184e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5281, 'grad_norm': 54.99174118041992, 'learning_rate': 3.9348659003831414e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2949, 'grad_norm': 16.771039962768555, 'learning_rate': 3.9272030651340996e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2315, 'grad_norm': 14.268911361694336, 'learning_rate': 3.919540229885058e-05, 'epoch': 0.65}\n",
      "{'loss': 1.0428, 'grad_norm': 27.135852813720703, 'learning_rate': 3.911877394636015e-05, 'epoch': 0.65}\n",
      "{'loss': 1.1066, 'grad_norm': 25.626636505126953, 'learning_rate': 3.9042145593869734e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3204, 'grad_norm': 2.067122220993042, 'learning_rate': 3.896551724137931e-05, 'epoch': 0.66}\n",
      "{'loss': 1.1024, 'grad_norm': 17.060747146606445, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8286, 'grad_norm': 32.74134826660156, 'learning_rate': 3.881226053639847e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6959, 'grad_norm': 69.70804595947266, 'learning_rate': 3.873563218390805e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1005, 'grad_norm': 7.780486583709717, 'learning_rate': 3.865900383141763e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5973, 'grad_norm': 36.464630126953125, 'learning_rate': 3.8582375478927204e-05, 'epoch': 0.69}\n",
      "{'loss': 1.6613, 'grad_norm': 439.5686340332031, 'learning_rate': 3.850574712643678e-05, 'epoch': 0.69}\n",
      "{'loss': 1.343, 'grad_norm': 48.55441665649414, 'learning_rate': 3.842911877394636e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7747, 'grad_norm': 133.14073181152344, 'learning_rate': 3.8352490421455936e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2332, 'grad_norm': 27.758262634277344, 'learning_rate': 3.827586206896552e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9507, 'grad_norm': 166.8175811767578, 'learning_rate': 3.81992337164751e-05, 'epoch': 0.71}\n",
      "{'loss': 2.2576, 'grad_norm': 32.30036163330078, 'learning_rate': 3.8122605363984674e-05, 'epoch': 0.71}\n",
      "{'loss': 0.9803, 'grad_norm': 22.707151412963867, 'learning_rate': 3.8045977011494256e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2104, 'grad_norm': 57.265037536621094, 'learning_rate': 3.796934865900383e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1748, 'grad_norm': 2.3678951263427734, 'learning_rate': 3.789272030651341e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7629, 'grad_norm': 30.87816619873047, 'learning_rate': 3.7816091954022994e-05, 'epoch': 0.73}\n",
      "{'loss': 1.4482, 'grad_norm': 52.350677490234375, 'learning_rate': 3.773946360153257e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2717, 'grad_norm': 14.804966926574707, 'learning_rate': 3.766283524904215e-05, 'epoch': 0.74}\n",
      "{'loss': 1.8054, 'grad_norm': 27.461742401123047, 'learning_rate': 3.7586206896551726e-05, 'epoch': 0.74}\n",
      "{'loss': 2.9569, 'grad_norm': 45.911888122558594, 'learning_rate': 3.75095785440613e-05, 'epoch': 0.75}\n",
      "{'loss': 1.4268, 'grad_norm': 41.444496154785156, 'learning_rate': 3.743295019157088e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3168, 'grad_norm': 7.867313861846924, 'learning_rate': 3.735632183908046e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4982, 'grad_norm': 8.401535034179688, 'learning_rate': 3.727969348659004e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6195, 'grad_norm': 20.482973098754883, 'learning_rate': 3.720306513409962e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1575, 'grad_norm': 5.3602094650268555, 'learning_rate': 3.7126436781609196e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6148, 'grad_norm': 19.725631713867188, 'learning_rate': 3.704980842911878e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6761, 'grad_norm': 62.29556655883789, 'learning_rate': 3.697318007662835e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1294, 'grad_norm': 10.793025016784668, 'learning_rate': 3.6896551724137934e-05, 'epoch': 0.79}\n",
      "{'loss': 1.0237, 'grad_norm': 37.99483871459961, 'learning_rate': 3.6819923371647516e-05, 'epoch': 0.79}\n",
      "{'loss': 0.6395, 'grad_norm': 31.265064239501953, 'learning_rate': 3.674329501915709e-05, 'epoch': 0.8}\n",
      "{'loss': 0.8922, 'grad_norm': 37.51065444946289, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 0.8774, 'grad_norm': 31.17631721496582, 'learning_rate': 3.659003831417625e-05, 'epoch': 0.8}\n",
      "{'loss': 0.5694, 'grad_norm': 24.252859115600586, 'learning_rate': 3.651340996168582e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2393, 'grad_norm': 16.789167404174805, 'learning_rate': 3.6436781609195404e-05, 'epoch': 0.81}\n",
      "{'loss': 0.9391, 'grad_norm': 54.160125732421875, 'learning_rate': 3.636015325670498e-05, 'epoch': 0.82}\n",
      "{'loss': 0.1447, 'grad_norm': 9.885538101196289, 'learning_rate': 3.628352490421456e-05, 'epoch': 0.82}\n",
      "{'loss': 0.8317, 'grad_norm': 25.46042251586914, 'learning_rate': 3.620689655172414e-05, 'epoch': 0.83}\n",
      "{'loss': 1.2424, 'grad_norm': 35.82029342651367, 'learning_rate': 3.613026819923372e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7775, 'grad_norm': 23.336563110351562, 'learning_rate': 3.60536398467433e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4904, 'grad_norm': 24.09977149963379, 'learning_rate': 3.5977011494252874e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0439, 'grad_norm': 11.715567588806152, 'learning_rate': 3.5900383141762456e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0813, 'grad_norm': 2.0658626556396484, 'learning_rate': 3.582375478927204e-05, 'epoch': 0.85}\n",
      "{'loss': 0.088, 'grad_norm': 1.1368317604064941, 'learning_rate': 3.5747126436781606e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6916, 'grad_norm': 34.50736618041992, 'learning_rate': 3.567049808429119e-05, 'epoch': 0.86}\n",
      "{'loss': 0.2324, 'grad_norm': 1.6293861865997314, 'learning_rate': 3.559386973180077e-05, 'epoch': 0.86}\n",
      "{'loss': 0.2419, 'grad_norm': 26.847639083862305, 'learning_rate': 3.5517241379310344e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0649, 'grad_norm': 10.707418441772461, 'learning_rate': 3.5440613026819926e-05, 'epoch': 0.87}\n",
      "{'loss': 1.8092, 'grad_norm': 906.5423583984375, 'learning_rate': 3.53639846743295e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1714, 'grad_norm': 99.3121337890625, 'learning_rate': 3.528735632183908e-05, 'epoch': 0.88}\n",
      "{'loss': 0.65, 'grad_norm': 97.2049789428711, 'learning_rate': 3.5210727969348664e-05, 'epoch': 0.89}\n",
      "{'loss': 1.0999, 'grad_norm': 197.67507934570312, 'learning_rate': 3.513409961685824e-05, 'epoch': 0.89}\n",
      "{'loss': 0.6004, 'grad_norm': 36.45253372192383, 'learning_rate': 3.505747126436782e-05, 'epoch': 0.9}\n",
      "{'loss': 1.8729, 'grad_norm': 98.77091979980469, 'learning_rate': 3.4980842911877396e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4749, 'grad_norm': 22.33960723876953, 'learning_rate': 3.490421455938698e-05, 'epoch': 0.91}\n",
      "{'loss': 2.3137, 'grad_norm': 41.14055252075195, 'learning_rate': 3.482758620689655e-05, 'epoch': 0.91}\n",
      "{'loss': 1.0697, 'grad_norm': 15.245061874389648, 'learning_rate': 3.475095785440613e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0802, 'grad_norm': 6.2571702003479, 'learning_rate': 3.467432950191571e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7593, 'grad_norm': 28.692012786865234, 'learning_rate': 3.459770114942529e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4613, 'grad_norm': 19.877593994140625, 'learning_rate': 3.4521072796934866e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8292, 'grad_norm': 43.63994216918945, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.93}\n",
      "{'loss': 1.7245, 'grad_norm': 27.884973526000977, 'learning_rate': 3.436781609195402e-05, 'epoch': 0.94}\n",
      "{'loss': 1.1607, 'grad_norm': 59.6701774597168, 'learning_rate': 3.4291187739463604e-05, 'epoch': 0.94}\n",
      "{'loss': 0.2054, 'grad_norm': 5.054838180541992, 'learning_rate': 3.4214559386973186e-05, 'epoch': 0.95}\n",
      "{'loss': 0.2319, 'grad_norm': 22.046201705932617, 'learning_rate': 3.413793103448276e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4008, 'grad_norm': 16.58085823059082, 'learning_rate': 3.406130268199234e-05, 'epoch': 0.96}\n",
      "{'loss': 1.1503, 'grad_norm': 24.54332733154297, 'learning_rate': 3.398467432950192e-05, 'epoch': 0.96}\n",
      "{'loss': 0.5212, 'grad_norm': 45.53590774536133, 'learning_rate': 3.390804597701149e-05, 'epoch': 0.97}\n",
      "{'loss': 1.3889, 'grad_norm': 27.52948570251465, 'learning_rate': 3.3831417624521074e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3814, 'grad_norm': 31.39657211303711, 'learning_rate': 3.375478927203065e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4239, 'grad_norm': 12.049534797668457, 'learning_rate': 3.367816091954023e-05, 'epoch': 0.98}\n",
      "{'loss': 1.5542, 'grad_norm': 52.446834564208984, 'learning_rate': 3.360153256704981e-05, 'epoch': 0.98}\n",
      "{'loss': 0.2271, 'grad_norm': 8.612115859985352, 'learning_rate': 3.352490421455939e-05, 'epoch': 0.99}\n",
      "{'loss': 0.4541, 'grad_norm': 536.4074096679688, 'learning_rate': 3.344827586206897e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0541, 'grad_norm': 7.109973430633545, 'learning_rate': 3.3371647509578544e-05, 'epoch': 1.0}\n",
      "{'loss': 0.5929, 'grad_norm': 14.016867637634277, 'learning_rate': 3.3295019157088126e-05, 'epoch': 1.0}\n",
      "{'loss': 0.8592, 'grad_norm': 96.97465515136719, 'learning_rate': 3.321839080459771e-05, 'epoch': 1.01}\n",
      "{'loss': 0.076, 'grad_norm': 20.55384635925293, 'learning_rate': 3.314176245210728e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1202, 'grad_norm': 7.98374605178833, 'learning_rate': 3.3065134099616864e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3369, 'grad_norm': 16.491670608520508, 'learning_rate': 3.298850574712644e-05, 'epoch': 1.02}\n",
      "{'loss': 0.6662, 'grad_norm': 342.1046142578125, 'learning_rate': 3.2911877394636014e-05, 'epoch': 1.03}\n",
      "{'loss': 1.2023, 'grad_norm': 20.1652889251709, 'learning_rate': 3.2835249042145596e-05, 'epoch': 1.03}\n",
      "{'loss': 1.039, 'grad_norm': 46.67622756958008, 'learning_rate': 3.275862068965517e-05, 'epoch': 1.03}\n",
      "{'loss': 0.2725, 'grad_norm': 28.651275634765625, 'learning_rate': 3.268199233716475e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1877, 'grad_norm': 14.07763385772705, 'learning_rate': 3.2605363984674334e-05, 'epoch': 1.04}\n",
      "{'loss': 0.2617, 'grad_norm': 6.3461995124816895, 'learning_rate': 3.252873563218391e-05, 'epoch': 1.05}\n",
      "{'loss': 0.1897, 'grad_norm': 0.4350833296775818, 'learning_rate': 3.245210727969349e-05, 'epoch': 1.05}\n",
      "{'loss': 0.6643, 'grad_norm': 21.018081665039062, 'learning_rate': 3.2375478927203066e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3916, 'grad_norm': 41.73001480102539, 'learning_rate': 3.229885057471265e-05, 'epoch': 1.06}\n",
      "{'loss': 0.4286, 'grad_norm': 22.129228591918945, 'learning_rate': 3.222222222222223e-05, 'epoch': 1.07}\n",
      "{'loss': 0.9088, 'grad_norm': 3.7943270206451416, 'learning_rate': 3.2145593869731804e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3269, 'grad_norm': 21.11482048034668, 'learning_rate': 3.206896551724138e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1995, 'grad_norm': 23.6027774810791, 'learning_rate': 3.1992337164750954e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1175, 'grad_norm': 20.198335647583008, 'learning_rate': 3.1915708812260536e-05, 'epoch': 1.09}\n",
      "{'loss': 0.4767, 'grad_norm': 26.458751678466797, 'learning_rate': 3.183908045977012e-05, 'epoch': 1.09}\n",
      "{'loss': 0.1305, 'grad_norm': 2.79957914352417, 'learning_rate': 3.176245210727969e-05, 'epoch': 1.09}\n",
      "{'loss': 0.5568, 'grad_norm': 6.632238388061523, 'learning_rate': 3.1685823754789274e-05, 'epoch': 1.1}\n",
      "{'loss': 0.092, 'grad_norm': 11.60191822052002, 'learning_rate': 3.160919540229885e-05, 'epoch': 1.1}\n",
      "{'loss': 0.296, 'grad_norm': 1.0180286169052124, 'learning_rate': 3.153256704980843e-05, 'epoch': 1.11}\n",
      "{'loss': 0.5223, 'grad_norm': 27.803558349609375, 'learning_rate': 3.145593869731801e-05, 'epoch': 1.11}\n",
      "{'loss': 0.7537, 'grad_norm': 17.899580001831055, 'learning_rate': 3.137931034482759e-05, 'epoch': 1.12}\n",
      "{'loss': 0.6885, 'grad_norm': 3.487083911895752, 'learning_rate': 3.130268199233717e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0525, 'grad_norm': 9.723483085632324, 'learning_rate': 3.1226053639846744e-05, 'epoch': 1.13}\n",
      "{'loss': 0.5256, 'grad_norm': 4.522920608520508, 'learning_rate': 3.114942528735632e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0526, 'grad_norm': 7.810652732849121, 'learning_rate': 3.10727969348659e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1942, 'grad_norm': 0.7635449767112732, 'learning_rate': 3.0996168582375476e-05, 'epoch': 1.14}\n",
      "{'loss': 1.1987, 'grad_norm': 1.1812466382980347, 'learning_rate': 3.091954022988506e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0135, 'grad_norm': 2.976229429244995, 'learning_rate': 3.084291187739464e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stacy/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c1bb5c41c7476e8855baf3f978f542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4718005359172821, 'eval_cer': 0.06099195710455764, 'eval_runtime': 5341.1868, 'eval_samples_per_second': 0.07, 'eval_steps_per_second': 0.035, 'epoch': 1.15}\n",
      "{'loss': 0.9668, 'grad_norm': 36.08891677856445, 'learning_rate': 3.0766283524904214e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3232, 'grad_norm': 25.068803787231445, 'learning_rate': 3.0689655172413796e-05, 'epoch': 1.16}\n",
      "{'loss': 0.9145, 'grad_norm': 228.50827026367188, 'learning_rate': 3.061302681992337e-05, 'epoch': 1.16}\n",
      "{'loss': 1.1571, 'grad_norm': 1.967034101486206, 'learning_rate': 3.053639846743295e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1474, 'grad_norm': 11.758615493774414, 'learning_rate': 3.045977011494253e-05, 'epoch': 1.17}\n",
      "{'loss': 0.6233, 'grad_norm': 48.88976287841797, 'learning_rate': 3.0383141762452112e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0039, 'grad_norm': 0.38103389739990234, 'learning_rate': 3.030651340996169e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0681, 'grad_norm': 5.229486465454102, 'learning_rate': 3.0229885057471262e-05, 'epoch': 1.19}\n",
      "{'loss': 0.4167, 'grad_norm': 17.789154052734375, 'learning_rate': 3.015325670498084e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0194, 'grad_norm': 1.7052044868469238, 'learning_rate': 3.0076628352490422e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2945, 'grad_norm': 16.688432693481445, 'learning_rate': 3e-05, 'epoch': 1.2}\n",
      "{'loss': 0.895, 'grad_norm': 12.157962799072266, 'learning_rate': 2.992337164750958e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0432, 'grad_norm': 3.2511510848999023, 'learning_rate': 2.9846743295019157e-05, 'epoch': 1.21}\n",
      "{'loss': 0.5301, 'grad_norm': 27.441448211669922, 'learning_rate': 2.9770114942528736e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0112, 'grad_norm': 2.425071954727173, 'learning_rate': 2.9693486590038317e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1117, 'grad_norm': 9.784749984741211, 'learning_rate': 2.9616858237547896e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1967, 'grad_norm': 0.3648700714111328, 'learning_rate': 2.9540229885057474e-05, 'epoch': 1.23}\n",
      "{'loss': 0.5135, 'grad_norm': 31.454652786254883, 'learning_rate': 2.9463601532567052e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3161, 'grad_norm': 11.049235343933105, 'learning_rate': 2.938697318007663e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1698, 'grad_norm': 9.95458698272705, 'learning_rate': 2.9310344827586206e-05, 'epoch': 1.24}\n",
      "{'loss': 0.5376, 'grad_norm': 1.0392388105392456, 'learning_rate': 2.9233716475095784e-05, 'epoch': 1.25}\n",
      "{'loss': 0.4682, 'grad_norm': 38.61139678955078, 'learning_rate': 2.9157088122605362e-05, 'epoch': 1.25}\n",
      "{'loss': 0.4479, 'grad_norm': 8.69627857208252, 'learning_rate': 2.9080459770114944e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0434, 'grad_norm': 6.594013214111328, 'learning_rate': 2.9003831417624522e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4414, 'grad_norm': 14.812759399414062, 'learning_rate': 2.89272030651341e-05, 'epoch': 1.26}\n",
      "{'loss': 0.2495, 'grad_norm': 16.801183700561523, 'learning_rate': 2.885057471264368e-05, 'epoch': 1.27}\n",
      "{'loss': 0.4108, 'grad_norm': 17.456035614013672, 'learning_rate': 2.8773946360153257e-05, 'epoch': 1.27}\n",
      "{'loss': 0.5083, 'grad_norm': 26.69118881225586, 'learning_rate': 2.869731800766284e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0267, 'grad_norm': 3.1557769775390625, 'learning_rate': 2.8620689655172417e-05, 'epoch': 1.28}\n",
      "{'loss': 1.1389, 'grad_norm': 3.3788843154907227, 'learning_rate': 2.8544061302681996e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1569, 'grad_norm': 3.5305755138397217, 'learning_rate': 2.8467432950191574e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2834, 'grad_norm': 0.4094604551792145, 'learning_rate': 2.839080459770115e-05, 'epoch': 1.3}\n",
      "{'loss': 0.1455, 'grad_norm': 12.76421070098877, 'learning_rate': 2.8314176245210727e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0369, 'grad_norm': 0.4236513078212738, 'learning_rate': 2.8237547892720306e-05, 'epoch': 1.31}\n",
      "{'loss': 0.1077, 'grad_norm': 0.38623398542404175, 'learning_rate': 2.8160919540229884e-05, 'epoch': 1.31}\n",
      "{'loss': 0.9838, 'grad_norm': 16.029624938964844, 'learning_rate': 2.8084291187739466e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2551, 'grad_norm': 1.0391247272491455, 'learning_rate': 2.8007662835249044e-05, 'epoch': 1.32}\n",
      "{'loss': 0.2595, 'grad_norm': 6.711269378662109, 'learning_rate': 2.7931034482758622e-05, 'epoch': 1.32}\n",
      "{'loss': 1.1, 'grad_norm': 48.3326301574707, 'learning_rate': 2.78544061302682e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0956, 'grad_norm': 2.8801960945129395, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3688, 'grad_norm': 24.438827514648438, 'learning_rate': 2.770114942528736e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0751, 'grad_norm': 3.8950695991516113, 'learning_rate': 2.762452107279694e-05, 'epoch': 1.34}\n",
      "{'loss': 0.053, 'grad_norm': 3.6819348335266113, 'learning_rate': 2.7547892720306517e-05, 'epoch': 1.35}\n",
      "{'loss': 1.1645, 'grad_norm': 228.3301239013672, 'learning_rate': 2.7471264367816092e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0085, 'grad_norm': 1.3422962427139282, 'learning_rate': 2.739463601532567e-05, 'epoch': 1.36}\n",
      "{'loss': 0.1707, 'grad_norm': 5.947787284851074, 'learning_rate': 2.731800766283525e-05, 'epoch': 1.36}\n",
      "{'loss': 0.093, 'grad_norm': 16.720169067382812, 'learning_rate': 2.7241379310344827e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1353, 'grad_norm': 13.116856575012207, 'learning_rate': 2.7164750957854406e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0178, 'grad_norm': 1.3627679347991943, 'learning_rate': 2.7088122605363987e-05, 'epoch': 1.37}\n",
      "{'loss': 0.4328, 'grad_norm': 34.83953857421875, 'learning_rate': 2.7011494252873566e-05, 'epoch': 1.38}\n",
      "{'loss': 1.0142, 'grad_norm': 21.996620178222656, 'learning_rate': 2.6934865900383144e-05, 'epoch': 1.38}\n",
      "{'loss': 1.1635, 'grad_norm': 27.561336517333984, 'learning_rate': 2.6858237547892722e-05, 'epoch': 1.39}\n",
      "{'loss': 0.4171, 'grad_norm': 8.31862735748291, 'learning_rate': 2.67816091954023e-05, 'epoch': 1.39}\n",
      "{'loss': 0.046, 'grad_norm': 7.817987442016602, 'learning_rate': 2.6704980842911883e-05, 'epoch': 1.4}\n",
      "{'loss': 0.7783, 'grad_norm': 14.712738037109375, 'learning_rate': 2.662835249042146e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0311, 'grad_norm': 2.213543176651001, 'learning_rate': 2.6551724137931032e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2247, 'grad_norm': 4.267396450042725, 'learning_rate': 2.647509578544061e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0194, 'grad_norm': 3.9383018016815186, 'learning_rate': 2.6398467432950192e-05, 'epoch': 1.42}\n",
      "{'loss': 0.6274, 'grad_norm': 18.325002670288086, 'learning_rate': 2.632183908045977e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0771, 'grad_norm': 10.515040397644043, 'learning_rate': 2.624521072796935e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1269, 'grad_norm': 0.11503314971923828, 'learning_rate': 2.6168582375478927e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0039, 'grad_norm': 0.26907581090927124, 'learning_rate': 2.6091954022988506e-05, 'epoch': 1.43}\n",
      "{'loss': 0.8706, 'grad_norm': 26.278051376342773, 'learning_rate': 2.6015325670498087e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2869, 'grad_norm': 11.132590293884277, 'learning_rate': 2.5938697318007666e-05, 'epoch': 1.44}\n",
      "{'loss': 0.376, 'grad_norm': 16.1245059967041, 'learning_rate': 2.5862068965517244e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1065, 'grad_norm': 8.497901916503906, 'learning_rate': 2.5785440613026822e-05, 'epoch': 1.45}\n",
      "{'loss': 0.4054, 'grad_norm': 52.21084213256836, 'learning_rate': 2.57088122605364e-05, 'epoch': 1.46}\n",
      "{'loss': 0.6299, 'grad_norm': 1.5445274114608765, 'learning_rate': 2.5632183908045976e-05, 'epoch': 1.46}\n",
      "{'loss': 0.8322, 'grad_norm': 67.72203826904297, 'learning_rate': 2.5555555555555554e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0286, 'grad_norm': 3.9508252143859863, 'learning_rate': 2.5478927203065132e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0742, 'grad_norm': 11.847434043884277, 'learning_rate': 2.5402298850574714e-05, 'epoch': 1.48}\n",
      "{'loss': 0.6047, 'grad_norm': 26.754907608032227, 'learning_rate': 2.5325670498084292e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1036, 'grad_norm': 41.42099380493164, 'learning_rate': 2.524904214559387e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0329, 'grad_norm': 3.7216007709503174, 'learning_rate': 2.517241379310345e-05, 'epoch': 1.49}\n",
      "{'loss': 0.7067, 'grad_norm': 56.27955627441406, 'learning_rate': 2.5095785440613027e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2511, 'grad_norm': 22.32761001586914, 'learning_rate': 2.501915708812261e-05, 'epoch': 1.5}\n",
      "{'loss': 0.3309, 'grad_norm': 19.216846466064453, 'learning_rate': 2.4942528735632184e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7209, 'grad_norm': 63.14171600341797, 'learning_rate': 2.4865900383141762e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1837, 'grad_norm': 0.1878148317337036, 'learning_rate': 2.478927203065134e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0128, 'grad_norm': 2.743068218231201, 'learning_rate': 2.4712643678160922e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0061, 'grad_norm': 0.3459358811378479, 'learning_rate': 2.46360153256705e-05, 'epoch': 1.52}\n",
      "{'loss': 0.018, 'grad_norm': 3.764086961746216, 'learning_rate': 2.455938697318008e-05, 'epoch': 1.53}\n",
      "{'loss': 0.1399, 'grad_norm': 13.674715042114258, 'learning_rate': 2.4482758620689654e-05, 'epoch': 1.53}\n",
      "{'loss': 0.5893, 'grad_norm': 6.892103672027588, 'learning_rate': 2.4406130268199236e-05, 'epoch': 1.54}\n",
      "{'loss': 0.6431, 'grad_norm': 6.329117774963379, 'learning_rate': 2.4329501915708814e-05, 'epoch': 1.54}\n",
      "{'loss': 0.1466, 'grad_norm': 14.502368927001953, 'learning_rate': 2.4252873563218392e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0281, 'grad_norm': 4.779452323913574, 'learning_rate': 2.417624521072797e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0013, 'grad_norm': 0.07109271734952927, 'learning_rate': 2.409961685823755e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1142, 'grad_norm': 14.794596672058105, 'learning_rate': 2.4022988505747127e-05, 'epoch': 1.56}\n",
      "{'loss': 0.1029, 'grad_norm': 1.844657063484192, 'learning_rate': 2.3946360153256706e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2721, 'grad_norm': 13.489616394042969, 'learning_rate': 2.3869731800766284e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0723, 'grad_norm': 3.5813891887664795, 'learning_rate': 2.3793103448275862e-05, 'epoch': 1.57}\n",
      "{'loss': 0.213, 'grad_norm': 1.0738292932510376, 'learning_rate': 2.3716475095785444e-05, 'epoch': 1.58}\n",
      "{'loss': 0.4316, 'grad_norm': 1.0617748498916626, 'learning_rate': 2.3639846743295022e-05, 'epoch': 1.58}\n",
      "{'loss': 0.4452, 'grad_norm': 59.95486068725586, 'learning_rate': 2.3563218390804597e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1073, 'grad_norm': 0.21286673843860626, 'learning_rate': 2.3486590038314176e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1575, 'grad_norm': 0.6711007356643677, 'learning_rate': 2.3409961685823757e-05, 'epoch': 1.6}\n",
      "{'loss': 0.3002, 'grad_norm': 0.7086246013641357, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0164, 'grad_norm': 2.837778091430664, 'learning_rate': 2.3256704980842914e-05, 'epoch': 1.6}\n",
      "{'loss': 0.4657, 'grad_norm': 109.98494720458984, 'learning_rate': 2.3180076628352492e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0051, 'grad_norm': 0.14881926774978638, 'learning_rate': 2.3103448275862067e-05, 'epoch': 1.61}\n",
      "{'loss': 1.3889, 'grad_norm': 21.893640518188477, 'learning_rate': 2.302681992337165e-05, 'epoch': 1.62}\n",
      "{'loss': 0.076, 'grad_norm': 0.2761772871017456, 'learning_rate': 2.2950191570881227e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0151, 'grad_norm': 0.1209774985909462, 'learning_rate': 2.2873563218390806e-05, 'epoch': 1.63}\n",
      "{'loss': 0.3937, 'grad_norm': 23.1674747467041, 'learning_rate': 2.2796934865900384e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0118, 'grad_norm': 3.6329870223999023, 'learning_rate': 2.2720306513409962e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3118, 'grad_norm': 48.52362060546875, 'learning_rate': 2.264367816091954e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0077, 'grad_norm': 1.2565406560897827, 'learning_rate': 2.256704980842912e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0092, 'grad_norm': 2.117856979370117, 'learning_rate': 2.2490421455938697e-05, 'epoch': 1.65}\n",
      "{'loss': 0.2476, 'grad_norm': 17.11014747619629, 'learning_rate': 2.2413793103448276e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3984, 'grad_norm': 68.30296325683594, 'learning_rate': 2.2337164750957857e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7218, 'grad_norm': 22.907127380371094, 'learning_rate': 2.2260536398467436e-05, 'epoch': 1.66}\n",
      "{'loss': 0.2151, 'grad_norm': 16.427108764648438, 'learning_rate': 2.218390804597701e-05, 'epoch': 1.67}\n",
      "{'loss': 0.4287, 'grad_norm': 12.08434772491455, 'learning_rate': 2.210727969348659e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0367, 'grad_norm': 59.97225570678711, 'learning_rate': 2.203065134099617e-05, 'epoch': 1.68}\n",
      "{'loss': 1.3347, 'grad_norm': 39.455570220947266, 'learning_rate': 2.195402298850575e-05, 'epoch': 1.68}\n",
      "{'loss': 0.036, 'grad_norm': 5.452568531036377, 'learning_rate': 2.1877394636015327e-05, 'epoch': 1.69}\n",
      "{'loss': 0.1025, 'grad_norm': 12.834673881530762, 'learning_rate': 2.1800766283524906e-05, 'epoch': 1.69}\n",
      "{'loss': 0.5525, 'grad_norm': 56.358154296875, 'learning_rate': 2.1724137931034484e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0323, 'grad_norm': 0.32566872239112854, 'learning_rate': 2.1647509578544062e-05, 'epoch': 1.7}\n",
      "{'loss': 0.13, 'grad_norm': 49.142024993896484, 'learning_rate': 2.157088122605364e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2728, 'grad_norm': 5.565400123596191, 'learning_rate': 2.149425287356322e-05, 'epoch': 1.71}\n",
      "{'loss': 0.023, 'grad_norm': 3.1962709426879883, 'learning_rate': 2.1417624521072797e-05, 'epoch': 1.71}\n",
      "{'loss': 0.1302, 'grad_norm': 1.3619674444198608, 'learning_rate': 2.134099616858238e-05, 'epoch': 1.72}\n",
      "{'loss': 0.1843, 'grad_norm': 19.974767684936523, 'learning_rate': 2.1264367816091954e-05, 'epoch': 1.72}\n",
      "{'loss': 0.259, 'grad_norm': 32.841796875, 'learning_rate': 2.1187739463601532e-05, 'epoch': 1.73}\n",
      "{'loss': 0.4942, 'grad_norm': 0.060941264033317566, 'learning_rate': 2.111111111111111e-05, 'epoch': 1.73}\n",
      "{'loss': 0.0151, 'grad_norm': 2.8866584300994873, 'learning_rate': 2.1034482758620692e-05, 'epoch': 1.74}\n",
      "{'loss': 0.4949, 'grad_norm': 14.344293594360352, 'learning_rate': 2.095785440613027e-05, 'epoch': 1.74}\n",
      "{'loss': 0.5986, 'grad_norm': 0.07065307348966599, 'learning_rate': 2.088122605363985e-05, 'epoch': 1.75}\n",
      "{'loss': 0.01, 'grad_norm': 0.5968424081802368, 'learning_rate': 2.0804597701149424e-05, 'epoch': 1.75}\n",
      "{'loss': 0.1086, 'grad_norm': 15.659324645996094, 'learning_rate': 2.0727969348659006e-05, 'epoch': 1.76}\n",
      "{'loss': 1.2036, 'grad_norm': 146.67698669433594, 'learning_rate': 2.0651340996168584e-05, 'epoch': 1.76}\n",
      "{'loss': 0.4183, 'grad_norm': 21.216764450073242, 'learning_rate': 2.0574712643678162e-05, 'epoch': 1.77}\n",
      "{'loss': 0.7632, 'grad_norm': 13.082181930541992, 'learning_rate': 2.049808429118774e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1148, 'grad_norm': 14.906065940856934, 'learning_rate': 2.042145593869732e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0035, 'grad_norm': 0.05415153503417969, 'learning_rate': 2.0344827586206897e-05, 'epoch': 1.78}\n",
      "{'loss': 0.6036, 'grad_norm': 15.919809341430664, 'learning_rate': 2.0268199233716476e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0251, 'grad_norm': 6.634100437164307, 'learning_rate': 2.0191570881226054e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3785, 'grad_norm': 14.709807395935059, 'learning_rate': 2.0114942528735632e-05, 'epoch': 1.79}\n",
      "{'loss': 0.0343, 'grad_norm': 0.32853105664253235, 'learning_rate': 2.0038314176245214e-05, 'epoch': 1.8}\n",
      "{'loss': 0.2526, 'grad_norm': 17.45387077331543, 'learning_rate': 1.9961685823754792e-05, 'epoch': 1.8}\n",
      "{'loss': 0.2046, 'grad_norm': 17.747230529785156, 'learning_rate': 1.9885057471264367e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0339, 'grad_norm': 1.5499554872512817, 'learning_rate': 1.9808429118773946e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0044, 'grad_norm': 1.431654453277588, 'learning_rate': 1.9731800766283527e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0157, 'grad_norm': 0.22619590163230896, 'learning_rate': 1.9655172413793106e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0193, 'grad_norm': 3.4524388313293457, 'learning_rate': 1.9578544061302684e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0047, 'grad_norm': 0.05469434708356857, 'learning_rate': 1.9501915708812262e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1036, 'grad_norm': 0.27660322189331055, 'learning_rate': 1.9425287356321837e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0408, 'grad_norm': 0.24523457884788513, 'learning_rate': 1.934865900383142e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3214, 'grad_norm': 9.826388359069824, 'learning_rate': 1.9272030651340997e-05, 'epoch': 1.84}\n",
      "{'loss': 0.006, 'grad_norm': 0.02843923680484295, 'learning_rate': 1.9195402298850576e-05, 'epoch': 1.85}\n",
      "{'loss': 0.0074, 'grad_norm': 0.48926112055778503, 'learning_rate': 1.9118773946360154e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2964, 'grad_norm': 32.80531692504883, 'learning_rate': 1.9042145593869732e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0695, 'grad_norm': 0.5232512950897217, 'learning_rate': 1.896551724137931e-05, 'epoch': 1.86}\n",
      "{'loss': 0.4766, 'grad_norm': 15.78906536102295, 'learning_rate': 1.888888888888889e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0612, 'grad_norm': 7.427515506744385, 'learning_rate': 1.8812260536398467e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0033, 'grad_norm': 0.21433307230472565, 'learning_rate': 1.8735632183908046e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0048, 'grad_norm': 0.3362243175506592, 'learning_rate': 1.8659003831417627e-05, 'epoch': 1.88}\n",
      "{'loss': 0.5735, 'grad_norm': 0.015394066460430622, 'learning_rate': 1.8582375478927206e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0056, 'grad_norm': 0.9662123918533325, 'learning_rate': 1.850574712643678e-05, 'epoch': 1.89}\n",
      "{'loss': 1.2425, 'grad_norm': 126.17882537841797, 'learning_rate': 1.842911877394636e-05, 'epoch': 1.89}\n",
      "{'loss': 0.1404, 'grad_norm': 8.14486026763916, 'learning_rate': 1.835249042145594e-05, 'epoch': 1.9}\n",
      "{'loss': 0.3991, 'grad_norm': 10.273544311523438, 'learning_rate': 1.827586206896552e-05, 'epoch': 1.9}\n",
      "{'loss': 0.0312, 'grad_norm': 6.979257583618164, 'learning_rate': 1.8199233716475097e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0035, 'grad_norm': 0.9456250667572021, 'learning_rate': 1.8122605363984676e-05, 'epoch': 1.91}\n",
      "{'loss': 0.1256, 'grad_norm': 19.90274429321289, 'learning_rate': 1.8045977011494254e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0968, 'grad_norm': 9.323458671569824, 'learning_rate': 1.7969348659003832e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0036, 'grad_norm': 0.026994116604328156, 'learning_rate': 1.789272030651341e-05, 'epoch': 1.93}\n",
      "{'loss': 0.0047, 'grad_norm': 0.7665154337882996, 'learning_rate': 1.781609195402299e-05, 'epoch': 1.93}\n",
      "{'loss': 0.0021, 'grad_norm': 0.30253684520721436, 'learning_rate': 1.7739463601532567e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0385, 'grad_norm': 0.2733064889907837, 'learning_rate': 1.766283524904215e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0755, 'grad_norm': 23.96329689025879, 'learning_rate': 1.7586206896551724e-05, 'epoch': 1.94}\n",
      "{'loss': 0.5793, 'grad_norm': 42.16766357421875, 'learning_rate': 1.7509578544061302e-05, 'epoch': 1.95}\n",
      "{'loss': 0.0042, 'grad_norm': 0.8370188474655151, 'learning_rate': 1.743295019157088e-05, 'epoch': 1.95}\n",
      "{'loss': 0.2662, 'grad_norm': 0.07593569904565811, 'learning_rate': 1.7356321839080462e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0548, 'grad_norm': 11.932561874389648, 'learning_rate': 1.727969348659004e-05, 'epoch': 1.96}\n",
      "{'loss': 0.4438, 'grad_norm': 24.607593536376953, 'learning_rate': 1.720306513409962e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0288, 'grad_norm': 7.575321197509766, 'learning_rate': 1.7126436781609194e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0036, 'grad_norm': 0.08808137476444244, 'learning_rate': 1.7049808429118776e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1093, 'grad_norm': 17.763233184814453, 'learning_rate': 1.6973180076628354e-05, 'epoch': 1.98}\n",
      "{'loss': 0.251, 'grad_norm': 12.557129859924316, 'learning_rate': 1.6896551724137932e-05, 'epoch': 1.99}\n",
      "{'loss': 0.3821, 'grad_norm': 14.551589965820312, 'learning_rate': 1.681992337164751e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0096, 'grad_norm': 1.1240911483764648, 'learning_rate': 1.674329501915709e-05, 'epoch': 2.0}\n",
      "{'loss': 0.1692, 'grad_norm': 29.258346557617188, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0046, 'grad_norm': 1.3921964168548584, 'learning_rate': 1.6590038314176246e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0395, 'grad_norm': 32.4626579284668, 'learning_rate': 1.6513409961685824e-05, 'epoch': 2.01}\n",
      "{'loss': 0.437, 'grad_norm': 39.11739730834961, 'learning_rate': 1.6436781609195402e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0003, 'grad_norm': 0.018075808882713318, 'learning_rate': 1.6360153256704984e-05, 'epoch': 2.02}\n",
      "{'loss': 0.1298, 'grad_norm': 0.10032981634140015, 'learning_rate': 1.628352490421456e-05, 'epoch': 2.02}\n",
      "{'loss': 0.5373, 'grad_norm': 0.8222871422767639, 'learning_rate': 1.6206896551724137e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0026, 'grad_norm': 0.34260043501853943, 'learning_rate': 1.6130268199233716e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0386, 'grad_norm': 1.0563430786132812, 'learning_rate': 1.6053639846743294e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0047, 'grad_norm': 0.27997228503227234, 'learning_rate': 1.5977011494252876e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0005, 'grad_norm': 0.03670385479927063, 'learning_rate': 1.5900383141762454e-05, 'epoch': 2.05}\n",
      "{'loss': 0.2641, 'grad_norm': 28.053680419921875, 'learning_rate': 1.582375478927203e-05, 'epoch': 2.05}\n",
      "{'loss': 0.009, 'grad_norm': 2.026216506958008, 'learning_rate': 1.5747126436781607e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0122, 'grad_norm': 4.205236434936523, 'learning_rate': 1.567049808429119e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0024, 'grad_norm': 0.3524240255355835, 'learning_rate': 1.5593869731800767e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0006, 'grad_norm': 0.015940802171826363, 'learning_rate': 1.5517241379310346e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2032, 'grad_norm': 25.586143493652344, 'learning_rate': 1.5440613026819924e-05, 'epoch': 2.07}\n",
      "{'loss': 0.0143, 'grad_norm': 0.08783408999443054, 'learning_rate': 1.5363984674329502e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0145, 'grad_norm': 0.038873542100191116, 'learning_rate': 1.528735632183908e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0006, 'grad_norm': 0.018963854759931564, 'learning_rate': 1.5210727969348659e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0114, 'grad_norm': 0.11737325042486191, 'learning_rate': 1.5134099616858237e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0022, 'grad_norm': 0.014346372336149216, 'learning_rate': 1.5057471264367817e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3322, 'grad_norm': 0.9318544864654541, 'learning_rate': 1.4980842911877396e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0019, 'grad_norm': 0.05496140941977501, 'learning_rate': 1.4904214559386972e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0053, 'grad_norm': 1.2073980569839478, 'learning_rate': 1.482758620689655e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0315, 'grad_norm': 7.612998962402344, 'learning_rate': 1.475095785440613e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0014, 'grad_norm': 0.07604210078716278, 'learning_rate': 1.4674329501915709e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0008, 'grad_norm': 0.1227581799030304, 'learning_rate': 1.459770114942529e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0507, 'grad_norm': 9.823295593261719, 'learning_rate': 1.4521072796934867e-05, 'epoch': 2.13}\n",
      "{'loss': 0.4607, 'grad_norm': 54.11090087890625, 'learning_rate': 1.4444444444444444e-05, 'epoch': 2.13}\n",
      "{'loss': 0.3084, 'grad_norm': 0.019302261993288994, 'learning_rate': 1.4367816091954022e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0025, 'grad_norm': 3.053591728210449, 'learning_rate': 1.4291187739463602e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0021, 'grad_norm': 2.3404135704040527, 'learning_rate': 1.421455938697318e-05, 'epoch': 2.15}\n",
      "{'loss': 0.2056, 'grad_norm': 13.591158866882324, 'learning_rate': 1.4137931034482759e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0008, 'grad_norm': 0.1770152896642685, 'learning_rate': 1.406130268199234e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0008, 'grad_norm': 0.02559572644531727, 'learning_rate': 1.3984674329501916e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0004, 'grad_norm': 0.026226403191685677, 'learning_rate': 1.3908045977011494e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0213, 'grad_norm': 0.7306098937988281, 'learning_rate': 1.3831417624521072e-05, 'epoch': 2.17}\n",
      "{'loss': 0.177, 'grad_norm': 0.013151826336979866, 'learning_rate': 1.3754789272030652e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0195, 'grad_norm': 5.788992881774902, 'learning_rate': 1.367816091954023e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0516, 'grad_norm': 0.3553740084171295, 'learning_rate': 1.360153256704981e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0016, 'grad_norm': 0.22097226977348328, 'learning_rate': 1.3524904214559386e-05, 'epoch': 2.19}\n",
      "{'loss': 0.252, 'grad_norm': 14.09430980682373, 'learning_rate': 1.3448275862068966e-05, 'epoch': 2.19}\n",
      "{'loss': 0.1025, 'grad_norm': 0.14258067309856415, 'learning_rate': 1.3371647509578544e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0078, 'grad_norm': 0.027850616723299026, 'learning_rate': 1.3295019157088122e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0415894016623497, 'learning_rate': 1.3218390804597702e-05, 'epoch': 2.21}\n",
      "{'loss': 0.0195, 'grad_norm': 16.330188751220703, 'learning_rate': 1.314176245210728e-05, 'epoch': 2.21}\n",
      "{'loss': 0.0068, 'grad_norm': 0.025835443288087845, 'learning_rate': 1.3065134099616857e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0012, 'grad_norm': 0.20793522894382477, 'learning_rate': 1.2988505747126436e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0559, 'grad_norm': 20.596538543701172, 'learning_rate': 1.2911877394636016e-05, 'epoch': 2.23}\n",
      "{'loss': 0.4668, 'grad_norm': 0.023730596527457237, 'learning_rate': 1.2835249042145594e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1235, 'grad_norm': 0.1032128781080246, 'learning_rate': 1.2758620689655174e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0115, 'grad_norm': 0.11514566838741302, 'learning_rate': 1.2681992337164752e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0004, 'grad_norm': 0.02698601968586445, 'learning_rate': 1.2605363984674329e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0053, 'grad_norm': 2.483269214630127, 'learning_rate': 1.2528735632183907e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0187, 'grad_norm': 5.75348424911499, 'learning_rate': 1.2452107279693487e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2141, 'grad_norm': 0.701779842376709, 'learning_rate': 1.2375478927203066e-05, 'epoch': 2.26}\n",
      "{'loss': 0.559, 'grad_norm': 14.858280181884766, 'learning_rate': 1.2298850574712644e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1615, 'grad_norm': 24.293298721313477, 'learning_rate': 1.2222222222222222e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0007, 'grad_norm': 0.13316679000854492, 'learning_rate': 1.21455938697318e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0696, 'grad_norm': 11.04581356048584, 'learning_rate': 1.206896551724138e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0623, 'grad_norm': 9.834486961364746, 'learning_rate': 1.1992337164750957e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0016, 'grad_norm': 0.11025277525186539, 'learning_rate': 1.1915708812260537e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0036, 'grad_norm': 0.06882952153682709, 'learning_rate': 1.1839080459770116e-05, 'epoch': 2.29}\n",
      "{'loss': 0.014, 'grad_norm': 1.774836778640747, 'learning_rate': 1.1762452107279694e-05, 'epoch': 2.29}\n",
      "{'loss': 0.3711, 'grad_norm': 0.07093764841556549, 'learning_rate': 1.1685823754789272e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57309eac82524cccb302f6a4dc9aa5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14444275200366974, 'eval_cer': 0.02379356568364611, 'eval_runtime': 5314.7655, 'eval_samples_per_second': 0.07, 'eval_steps_per_second': 0.035, 'epoch': 2.3}\n",
      "{'loss': 0.074, 'grad_norm': 10.758091926574707, 'learning_rate': 1.1609195402298852e-05, 'epoch': 2.3}\n",
      "{'loss': 0.1902, 'grad_norm': 0.0923178493976593, 'learning_rate': 1.1532567049808429e-05, 'epoch': 2.31}\n",
      "{'loss': 0.0063, 'grad_norm': 0.6164608001708984, 'learning_rate': 1.1455938697318007e-05, 'epoch': 2.31}\n",
      "{'loss': 0.0173, 'grad_norm': 2.955955743789673, 'learning_rate': 1.1379310344827587e-05, 'epoch': 2.32}\n",
      "{'loss': 0.008, 'grad_norm': 0.07959303259849548, 'learning_rate': 1.1302681992337164e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0251, 'grad_norm': 0.10282594710588455, 'learning_rate': 1.1226053639846744e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0086, 'grad_norm': 2.536823034286499, 'learning_rate': 1.1149425287356322e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0069, 'grad_norm': 2.3708229064941406, 'learning_rate': 1.10727969348659e-05, 'epoch': 2.34}\n",
      "{'loss': 0.3241, 'grad_norm': 36.09623336791992, 'learning_rate': 1.0996168582375479e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0146, 'grad_norm': 0.03417631611227989, 'learning_rate': 1.091954022988506e-05, 'epoch': 2.34}\n",
      "{'loss': 0.275, 'grad_norm': 13.294302940368652, 'learning_rate': 1.0842911877394636e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3008, 'grad_norm': 1.543670654296875, 'learning_rate': 1.0766283524904216e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0007, 'grad_norm': 2.153331995010376, 'learning_rate': 1.0689655172413794e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0058, 'grad_norm': 0.766606330871582, 'learning_rate': 1.0613026819923372e-05, 'epoch': 2.36}\n",
      "{'loss': 0.003, 'grad_norm': 1.0741785764694214, 'learning_rate': 1.053639846743295e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0006, 'grad_norm': 0.007932980544865131, 'learning_rate': 1.0459770114942529e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0157, 'grad_norm': 0.03157827630639076, 'learning_rate': 1.0383141762452107e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0007, 'grad_norm': 0.16319698095321655, 'learning_rate': 1.0306513409961686e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0007, 'grad_norm': 0.4339108467102051, 'learning_rate': 1.0229885057471266e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0008, 'grad_norm': 0.20646104216575623, 'learning_rate': 1.0153256704980842e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0147, 'grad_norm': 0.08804399520158768, 'learning_rate': 1.0076628352490422e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0835, 'grad_norm': 0.0268273763358593, 'learning_rate': 1e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0015, 'grad_norm': 0.20916171371936798, 'learning_rate': 9.923371647509579e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0137, 'grad_norm': 10.249591827392578, 'learning_rate': 9.846743295019157e-06, 'epoch': 2.41}\n",
      "{'loss': 0.0493, 'grad_norm': 5.936995029449463, 'learning_rate': 9.770114942528738e-06, 'epoch': 2.41}\n",
      "{'loss': 0.0007, 'grad_norm': 0.08153250813484192, 'learning_rate': 9.693486590038314e-06, 'epoch': 2.42}\n",
      "{'loss': 0.8641, 'grad_norm': 20.2965030670166, 'learning_rate': 9.616858237547892e-06, 'epoch': 2.42}\n",
      "{'loss': 0.0003, 'grad_norm': 0.02312636561691761, 'learning_rate': 9.540229885057472e-06, 'epoch': 2.43}\n",
      "{'loss': 0.0316, 'grad_norm': 0.5836512446403503, 'learning_rate': 9.463601532567049e-06, 'epoch': 2.43}\n",
      "{'loss': 0.2419, 'grad_norm': 28.539880752563477, 'learning_rate': 9.386973180076629e-06, 'epoch': 2.44}\n",
      "{'loss': 0.1982, 'grad_norm': 0.8075782060623169, 'learning_rate': 9.310344827586207e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0018, 'grad_norm': 0.41068699955940247, 'learning_rate': 9.233716475095786e-06, 'epoch': 2.45}\n",
      "{'loss': 0.0004, 'grad_norm': 0.06500038504600525, 'learning_rate': 9.157088122605364e-06, 'epoch': 2.45}\n",
      "{'loss': 0.0012, 'grad_norm': 0.19084623456001282, 'learning_rate': 9.080459770114944e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0169, 'grad_norm': 5.31392240524292, 'learning_rate': 9.00383141762452e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0016, 'grad_norm': 0.27579978108406067, 'learning_rate': 8.9272030651341e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0014, 'grad_norm': 0.3742378354072571, 'learning_rate': 8.85057471264368e-06, 'epoch': 2.47}\n",
      "{'loss': 0.0006, 'grad_norm': 0.07694944739341736, 'learning_rate': 8.773946360153257e-06, 'epoch': 2.47}\n",
      "{'loss': 0.0008, 'grad_norm': 0.16919520497322083, 'learning_rate': 8.697318007662836e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0887, 'grad_norm': 33.006168365478516, 'learning_rate': 8.620689655172414e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0043, 'grad_norm': 0.02998390607535839, 'learning_rate': 8.544061302681992e-06, 'epoch': 2.49}\n",
      "{'loss': 0.001, 'grad_norm': 0.19607602059841156, 'learning_rate': 8.46743295019157e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0134, 'grad_norm': 0.1353103220462799, 'learning_rate': 8.39080459770115e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0054, 'grad_norm': 0.44404736161231995, 'learning_rate': 8.314176245210727e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1065, 'grad_norm': 118.27869415283203, 'learning_rate': 8.237547892720307e-06, 'epoch': 2.51}\n",
      "{'loss': 0.0002, 'grad_norm': 0.028196906670928, 'learning_rate': 8.160919540229886e-06, 'epoch': 2.51}\n",
      "{'loss': 0.4687, 'grad_norm': 36.51830291748047, 'learning_rate': 8.084291187739464e-06, 'epoch': 2.51}\n",
      "{'loss': 0.0005, 'grad_norm': 0.05527212470769882, 'learning_rate': 8.007662835249042e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0296, 'grad_norm': 2.5076851844787598, 'learning_rate': 7.93103448275862e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0048, 'grad_norm': 0.24552787840366364, 'learning_rate': 7.854406130268199e-06, 'epoch': 2.53}\n",
      "{'loss': 0.0012, 'grad_norm': 0.22111617028713226, 'learning_rate': 7.777777777777777e-06, 'epoch': 2.53}\n",
      "{'loss': 0.0098, 'grad_norm': 5.648054122924805, 'learning_rate': 7.701149425287357e-06, 'epoch': 2.54}\n",
      "{'loss': 0.0213, 'grad_norm': 7.271219730377197, 'learning_rate': 7.624521072796935e-06, 'epoch': 2.54}\n",
      "{'loss': 0.0004, 'grad_norm': 0.029084665700793266, 'learning_rate': 7.547892720306514e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0045, 'grad_norm': 0.014334038831293583, 'learning_rate': 7.4712643678160925e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0005, 'grad_norm': 0.032578956335783005, 'learning_rate': 7.394636015325671e-06, 'epoch': 2.56}\n",
      "{'loss': 0.3201, 'grad_norm': 18.89636993408203, 'learning_rate': 7.318007662835249e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0013, 'grad_norm': 0.30877456068992615, 'learning_rate': 7.241379310344828e-06, 'epoch': 2.57}\n",
      "{'loss': 0.1989, 'grad_norm': 12.896905899047852, 'learning_rate': 7.164750957854406e-06, 'epoch': 2.57}\n",
      "{'loss': 0.0018, 'grad_norm': 0.3743211328983307, 'learning_rate': 7.088122605363985e-06, 'epoch': 2.57}\n",
      "{'loss': 0.0013, 'grad_norm': 0.21704985201358795, 'learning_rate': 7.011494252873564e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0025, 'grad_norm': 0.5965720415115356, 'learning_rate': 6.934865900383142e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0006, 'grad_norm': 0.11288651823997498, 'learning_rate': 6.858237547892721e-06, 'epoch': 2.59}\n",
      "{'loss': 0.0408, 'grad_norm': 0.0436631441116333, 'learning_rate': 6.7816091954023e-06, 'epoch': 2.59}\n",
      "{'loss': 0.0008, 'grad_norm': 0.18897663056850433, 'learning_rate': 6.7049808429118775e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0111, 'grad_norm': 0.04561862349510193, 'learning_rate': 6.628352490421457e-06, 'epoch': 2.6}\n",
      "{'loss': 0.1081, 'grad_norm': 28.863229751586914, 'learning_rate': 6.551724137931035e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0005, 'grad_norm': 0.053900811821222305, 'learning_rate': 6.475095785440613e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0029, 'grad_norm': 0.013898856937885284, 'learning_rate': 6.398467432950192e-06, 'epoch': 2.62}\n",
      "{'loss': 0.0023, 'grad_norm': 0.5752841234207153, 'learning_rate': 6.321839080459771e-06, 'epoch': 2.62}\n",
      "{'loss': 0.0011, 'grad_norm': 0.05840574949979782, 'learning_rate': 6.245210727969348e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0022, 'grad_norm': 1.2057318687438965, 'learning_rate': 6.1685823754789275e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0001, 'grad_norm': 0.005085651762783527, 'learning_rate': 6.091954022988506e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0019, 'grad_norm': 0.5054636001586914, 'learning_rate': 6.015325670498084e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0009, 'grad_norm': 0.07949100434780121, 'learning_rate': 5.938697318007663e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0007, 'grad_norm': 0.1284974217414856, 'learning_rate': 5.862068965517242e-06, 'epoch': 2.65}\n",
      "{'loss': 0.0004, 'grad_norm': 0.02232605405151844, 'learning_rate': 5.78544061302682e-06, 'epoch': 2.65}\n",
      "{'loss': 0.0036, 'grad_norm': 0.8459115624427795, 'learning_rate': 5.708812260536399e-06, 'epoch': 2.66}\n",
      "{'loss': 0.0009, 'grad_norm': 0.041951630264520645, 'learning_rate': 5.6321839080459775e-06, 'epoch': 2.66}\n",
      "{'loss': 0.0056, 'grad_norm': 0.972436785697937, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0117, 'grad_norm': 0.9184460043907166, 'learning_rate': 5.478927203065134e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0073, 'grad_norm': 3.2798399925231934, 'learning_rate': 5.4022988505747125e-06, 'epoch': 2.68}\n",
      "{'loss': 0.1823, 'grad_norm': 7.430588245391846, 'learning_rate': 5.325670498084291e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0011, 'grad_norm': 0.2693133056163788, 'learning_rate': 5.24904214559387e-06, 'epoch': 2.69}\n",
      "{'loss': 0.0112, 'grad_norm': 0.049352262169122696, 'learning_rate': 5.172413793103448e-06, 'epoch': 2.69}\n",
      "{'loss': 0.0006, 'grad_norm': 0.008710168302059174, 'learning_rate': 5.095785440613027e-06, 'epoch': 2.69}\n",
      "{'loss': 0.0002, 'grad_norm': 0.012889662757515907, 'learning_rate': 5.019157088122606e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0057, 'grad_norm': 0.012188896536827087, 'learning_rate': 4.942528735632184e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0012, 'grad_norm': 0.12241891026496887, 'learning_rate': 4.8659003831417625e-06, 'epoch': 2.71}\n",
      "{'loss': 0.0006, 'grad_norm': 0.023097779601812363, 'learning_rate': 4.789272030651342e-06, 'epoch': 2.71}\n",
      "{'loss': 0.3384, 'grad_norm': 17.393245697021484, 'learning_rate': 4.71264367816092e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0027, 'grad_norm': 0.12123376131057739, 'learning_rate': 4.636015325670498e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0005, 'grad_norm': 0.03427440673112869, 'learning_rate': 4.559386973180077e-06, 'epoch': 2.73}\n",
      "{'loss': 0.0007, 'grad_norm': 0.12296212464570999, 'learning_rate': 4.482758620689655e-06, 'epoch': 2.73}\n",
      "{'loss': 0.001, 'grad_norm': 0.02836248278617859, 'learning_rate': 4.406130268199233e-06, 'epoch': 2.74}\n",
      "{'loss': 0.107, 'grad_norm': 18.52675437927246, 'learning_rate': 4.3295019157088125e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1052, 'grad_norm': 15.5634183883667, 'learning_rate': 4.252873563218391e-06, 'epoch': 2.74}\n",
      "{'loss': 0.001, 'grad_norm': 0.08478755503892899, 'learning_rate': 4.176245210727969e-06, 'epoch': 2.75}\n",
      "{'loss': 0.0004, 'grad_norm': 0.09930498898029327, 'learning_rate': 4.099616858237548e-06, 'epoch': 2.75}\n",
      "{'loss': 0.0002, 'grad_norm': 0.006696152500808239, 'learning_rate': 4.022988505747127e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0006, 'grad_norm': 0.364406019449234, 'learning_rate': 3.946360153256705e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0005, 'grad_norm': 0.013315566815435886, 'learning_rate': 3.869731800766284e-06, 'epoch': 2.77}\n",
      "{'loss': 0.6309, 'grad_norm': 111.17123413085938, 'learning_rate': 3.793103448275862e-06, 'epoch': 2.77}\n",
      "{'loss': 0.0106, 'grad_norm': 3.200380563735962, 'learning_rate': 3.7164750957854404e-06, 'epoch': 2.78}\n",
      "{'loss': 0.0035, 'grad_norm': 0.6875298023223877, 'learning_rate': 3.6398467432950196e-06, 'epoch': 2.78}\n",
      "{'loss': 0.008, 'grad_norm': 2.518615245819092, 'learning_rate': 3.563218390804598e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0032, 'grad_norm': 0.806597888469696, 'learning_rate': 3.4865900383141762e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0002, 'grad_norm': 0.013528339564800262, 'learning_rate': 3.409961685823755e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0004, 'grad_norm': 0.13393203914165497, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0031, 'grad_norm': 1.050938606262207, 'learning_rate': 3.2567049808429117e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0005, 'grad_norm': 0.009596669115126133, 'learning_rate': 3.180076628352491e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0002, 'grad_norm': 0.013343257829546928, 'learning_rate': 3.103448275862069e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0004, 'grad_norm': 0.037723347544670105, 'learning_rate': 3.026819923371648e-06, 'epoch': 2.82}\n",
      "{'loss': 0.2235, 'grad_norm': 0.312950998544693, 'learning_rate': 2.9501915708812262e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0033, 'grad_norm': 1.098371148109436, 'learning_rate': 2.8735632183908046e-06, 'epoch': 2.83}\n",
      "{'loss': 0.0007, 'grad_norm': 0.1297466903924942, 'learning_rate': 2.7969348659003833e-06, 'epoch': 2.83}\n",
      "{'loss': 0.0002, 'grad_norm': 0.025891317054629326, 'learning_rate': 2.7203065134099617e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0015, 'grad_norm': 0.44600895047187805, 'learning_rate': 2.6436781609195404e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0015, 'grad_norm': 0.3678137958049774, 'learning_rate': 2.567049808429119e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0015, 'grad_norm': 0.014547138474881649, 'learning_rate': 2.4904214559386975e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0004, 'grad_norm': 0.05385446548461914, 'learning_rate': 2.413793103448276e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0014, 'grad_norm': 0.01060924306511879, 'learning_rate': 2.3371647509578546e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0148, 'grad_norm': 0.0033010372426360846, 'learning_rate': 2.260536398467433e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0002, 'grad_norm': 0.006489024963229895, 'learning_rate': 2.1839080459770117e-06, 'epoch': 2.87}\n",
      "{'loss': 0.0004, 'grad_norm': 0.02817845717072487, 'learning_rate': 2.1072796934865904e-06, 'epoch': 2.87}\n",
      "{'loss': 0.0013, 'grad_norm': 0.16319485008716583, 'learning_rate': 2.0306513409961687e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0006, 'grad_norm': 0.08594264835119247, 'learning_rate': 1.954022988505747e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0004, 'grad_norm': 0.02065376751124859, 'learning_rate': 1.8773946360153258e-06, 'epoch': 2.89}\n",
      "{'loss': 0.0913, 'grad_norm': 1.9364179372787476, 'learning_rate': 1.8007662835249042e-06, 'epoch': 2.89}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0587342344224453, 'learning_rate': 1.724137931034483e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0004, 'grad_norm': 0.10644964873790741, 'learning_rate': 1.6475095785440615e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005414362996816635, 'learning_rate': 1.5708812260536398e-06, 'epoch': 2.91}\n",
      "{'loss': 0.125, 'grad_norm': 21.939035415649414, 'learning_rate': 1.4942528735632185e-06, 'epoch': 2.91}\n",
      "{'loss': 0.0037, 'grad_norm': 0.9194055795669556, 'learning_rate': 1.4176245210727969e-06, 'epoch': 2.91}\n",
      "{'loss': 0.0005, 'grad_norm': 0.08876802027225494, 'learning_rate': 1.3409961685823756e-06, 'epoch': 2.92}\n",
      "{'loss': 0.003, 'grad_norm': 0.20867420732975006, 'learning_rate': 1.2643678160919542e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0764, 'grad_norm': 11.499734878540039, 'learning_rate': 1.1877394636015325e-06, 'epoch': 2.93}\n",
      "{'loss': 0.0008, 'grad_norm': 0.030293039977550507, 'learning_rate': 1.1111111111111112e-06, 'epoch': 2.93}\n",
      "{'loss': 0.0005, 'grad_norm': 0.08145826309919357, 'learning_rate': 1.0344827586206898e-06, 'epoch': 2.94}\n",
      "{'loss': 0.0003, 'grad_norm': 0.018990689888596535, 'learning_rate': 9.578544061302681e-07, 'epoch': 2.94}\n",
      "{'loss': 0.0018, 'grad_norm': 1.2914958000183105, 'learning_rate': 8.812260536398469e-07, 'epoch': 2.95}\n",
      "{'loss': 0.0037, 'grad_norm': 0.5333684086799622, 'learning_rate': 8.045977011494253e-07, 'epoch': 2.95}\n",
      "{'loss': 0.0004, 'grad_norm': 0.021622631698846817, 'learning_rate': 7.279693486590039e-07, 'epoch': 2.96}\n",
      "{'loss': 0.0022, 'grad_norm': 0.5520050525665283, 'learning_rate': 6.513409961685824e-07, 'epoch': 2.96}\n",
      "{'loss': 0.0005, 'grad_norm': 0.018371568992733955, 'learning_rate': 5.747126436781609e-07, 'epoch': 2.97}\n",
      "{'loss': 0.0004, 'grad_norm': 0.05267301946878433, 'learning_rate': 4.980842911877395e-07, 'epoch': 2.97}\n",
      "{'loss': 0.0008, 'grad_norm': 0.6930810809135437, 'learning_rate': 4.2145593869731797e-07, 'epoch': 2.97}\n",
      "{'loss': 0.001, 'grad_norm': 0.43106234073638916, 'learning_rate': 3.4482758620689656e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0005, 'grad_norm': 0.008767891675233841, 'learning_rate': 2.681992337164751e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0038, 'grad_norm': 0.027818996459245682, 'learning_rate': 1.9157088122605365e-07, 'epoch': 2.99}\n",
      "{'loss': 0.0005, 'grad_norm': 0.08021670579910278, 'learning_rate': 1.1494252873563219e-07, 'epoch': 2.99}\n",
      "{'loss': 0.001, 'grad_norm': 0.2648131549358368, 'learning_rate': 3.831417624521073e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 48890.5283, 'train_samples_per_second': 0.053, 'train_steps_per_second': 0.027, 'train_loss': 0.5062505748377283, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.5062505748377283, metrics={'train_runtime': 48890.5283, 'train_samples_per_second': 0.053, 'train_steps_per_second': 0.027, 'total_flos': 1.9507794929264886e+18, 'train_loss': 0.5062505748377283, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 64, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./results/trocr-finetuned')\n",
    "processor.save_pretrained('./results/trocr-finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
